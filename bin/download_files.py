#!/usr/bin/env python3

import logging

import click

from osp_scraper.tasks import crawl

log = logging.getLogger('file_crawler')

@click.command()
@click.argument('csv_file', type=click.Path(exists=True))
@click.option(
    '--local',
    default=False,
    is_flag=True,
    help="Run spiders locally instead of queueing them"
)
def main(csv_file, local):
    """
    Downloads files from a specifically formatted CSV generated by OutWit
    (https://www.outwit.com/).  The CSV must have two columns, one titled
    'Source Url' and the other titled 'Document Url'.

    For more details, see `file_downloader.py` in `osp_scraper.spiders`.
    """
    crawl_func = crawl if local else crawl.delay

    crawl_func("file_downloader", csv_file=csv_file)

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    main()
